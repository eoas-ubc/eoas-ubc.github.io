# Teaching and learning with Dashboards

## Introduction

This page summarizes ways that dashboards have been introduced to EOAS faculty and students for teaching and learning purposes. Design and deployment guidelines are provided on separate pages.

## General feedback about using dashboards in lessons:

* In all the courses using new dashboards we are seeing the same importance of allowing students time to familiarize with the tool before asking them to make good use of it. Students cannot solve problems with a new tool unless they have time to familiarize with the tool. There are 3 aspects they are wrestling with: 1) new concepts, 2) a new tool, and 3) a "problem" to solve (eg "_what happens to the water divide, both mathematically and conceptually_").
* If possible, ask them to familiarize with the tool before coming to class, perhaps with a few pointers about what to look for. Then they will come to class more ready to use the tool productively.
* Or, have them explore a little in class at the end of one lesson, then pick up the "real" task in the following lesson.
* Perhaps the first questions they are given can be "trivial" (i.e. more about the tool than the concepts). Then the real problem you want them to solve comes after that.
* Activity instructions on lecture slides can work for inclass work. However, it is more effective to have a worksheet with settings, questions, and spaces for answering.
* Questions to solve can be more "interesting" to students (i.e. more motivational) if they are in terms of the consequences to people, property, ecosystems, or whatever, rather than simply abstract or theoretical questions. This is about connecting concepts to reality.

## Recommendations

* needs fleshing out.
* Encourage students to pose questions - do this strategically; quote from Kastens, Zrada & Turrin, 2019 (refs below): "Encouragingly, over 70% of participants generated at least one question at the highest Bloom’s level. Implications for instruction include that assigned question-asking can be an opportunity to engage all students in question asking, and that students can ask good questions about complex data before the data are explained to them."

## Third party references

* **How guidance affects student engagement with an interactive simulation**, J. M. Chamberlain, K. Lancaster, R. Parson, & K. K. Perkins. Chemistry Education Research and Practice. 15 p. 628-638, 2014.
* **Tools for high-tech tool use: A framework and heuristics for using interactive simulations**, Rehn, D. A., Moore, E. B., Podolefsky, N. S., & Finkelstein, N., JoTLT. 2(1), p. 31-55, 2013.
* **Teaching Physics using PhET Simulations**, C. Wieman, W. Adams, P. Loeblein, and K. Perkins, The Physics Teacher, 2010.
* **Many scholarly references** at [https://phet.colorado.edu/en/research](https://phet.colorado.edu/en/research).
* **What Kinds of Questions Do Students Ask While Exploring Data Visualizations?**, Kastens, Kim A., Melissa Zrada, and Margie Turrin.  Journal of Geoscience Education 68, no. 3 (July 2, 2020): 199–219. https://doi.org/10.1080/10899995.2019.1675447.
* **Creating Effective Interactive Tools for Learning:  Insights from the PhET Interactive Simulations Project**, Perkins, Katherine, Noah Podolefsky, Kelly Lancaster, and Emily Moore. In Proceedings of World Conference on Educational Multimedia, Hypermedia and Telecommunications 2012, 2012:436–41, 2012. http://editlib.org/p/40781.
* See also references on the **[QuEST](https://blogs.ubc.ca/eoasquest)** project [references page](https://blogs.ubc.ca/eoasquest/references/).