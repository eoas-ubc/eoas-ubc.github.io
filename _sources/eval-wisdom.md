# Project Evaluation and Wisdom gained

## Evaluation questions, data, results and implications

For guidelines see the project evaluation [worksheet](https://docs.google.com/document/d/1Sy_qDbaRvyyFw2NM8jc_0Xge2LpbL2Cxb9cFv9dQKxE/edit) at the TLEF project support site.

## Student reactions

Short surveys can be included as part of assignments that use the app. This was done for the oceanography dataviewer (EOSC 372, Nov 2021), the first version of the C02 anomaly app (ENVR 300, Jan 2021), and the IPCC-based activity in EOSC 112 (Nov. 2021).

A short (< 5 mins) survey using the UBC Qualtrics system can be easily embedded at the end of the app; students can be asked (or required) to finish their use of the app by completing the survey. This was done for the global temperature factors app, and a very few responses were obtained from EOSC 112, EOSC 340 and EOSC 425.

Observations of the class during first use of the app in a classroom setting can be used to gauge the impact of the app's use by instructors and students. This was done for EOSC 325, and EOSC 112's IPCC Climate Atlas-based activity. 

Feedback data are included on individual pages summarizing OCESE results for each [course](course_materials.md).

## Faculty participation

1. When we offer to build dashboards, several instructors were keen but slow to participate, usually owing to lack of time or energy to innovate. (eg Mohr’s Circle app, ENVR 300 in fall 2021, hydrogeology.
2. Three were produced for EOSC325. There was good engagement early on, considering we didn’t get apps onto servers until late in the design cycle.
3. Instructors teaching courses with existing or newly introduced climate science components were keen to participate. One app was produced for use in at leat 5 courses, but actually used in 3 courses. A second activity was designed but the pedagogy needed development. Instructors agree to pilot the idea, then did not follow through.
4. Fine tuning for actual use in class did not happen until very near the actual use.
   1. Ocgy was being reviewed and a corresponding assignment developed 3 weeks before implementation.
   2. Eosc325 was being reviewed and fine tuned just days before final use.

**Conclusions / recommendations:**

1. Involve instructors in the design cycle as early as possible. 
2. If they are not prepared to run code themselves, use Heroku to mount and demo early versions.
3. Agree to specific milestones with short (a week or two) small-scale deliverables and corresponding meetings. Otherwise the new ideas quickly end up on the back burner.
4. Make sure app is deployed at least 2weeks before planned use in class or assign.

## Dashboards; general lessons learned

1. Instructors need time to explore, play, and iterate on learning activities.

2. Assignments need to establish expectations or purposes. Add a single learning goal (or two if it’s a longer assignment) to the assignment (not directly on the dashboard.

See separate pages with guidelines for [dashboard development](dashboards-howto.md) and [dashboard deployment](dashboards-deploy.md).

## Recommendations beyond OCESE
